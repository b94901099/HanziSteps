//
//  LearningView.swift
//  HanziSteps
//
//  Created by Sheng-Lun Chen on 7/31/25.
//

import SwiftUI
import SwiftData
import AVFoundation

struct LearningView: View {
    @Environment(\.modelContext) private var modelContext
    @Environment(\.dismiss) private var dismiss
    @Query private var sentences: [Sentence]
    @State private var synthesizer = AVSpeechSynthesizer()

    var body: some View {
        VStack(spacing: 20) {
            // å¥å­å±•ç¤ºå€
            Text(sentences.first?.text ?? "ç„¡å¥å­")
                .font(.title)
                .padding()
                .multilineTextAlignment(.center)
            
            // å–®å­—å±•ç¤ºå€
            if let sentence = sentences.first {
                LazyVGrid(columns: Array(repeating: GridItem(.flexible()), count: 4), spacing: 12) {
                    ForEach(sentence.words, id: \.self) { word in
                        Text(word)
                            .font(.title2)
                            .fontWeight(.semibold)
                            .foregroundColor(.black)
                            .frame(width: 60, height: 60)
                            .background(Color.yellow)
                            .cornerRadius(8)
                    }
                }
                .padding(.horizontal, 20)
            }
            
            Spacer()
            
            // æœ—è®€æŒ‰éˆ•
            Button("æœ—è®€å¥å­") {
                speakSentence()
            }
            .padding()
            .background(Color.blue)
            .foregroundColor(.white)
            .cornerRadius(10)
            
            Spacer()
        }
        .navigationTitle("èªå­—ç·´ç¿’")
        .navigationBarTitleDisplayMode(.inline)
        .toolbar {
            ToolbarItem(placement: .navigationBarLeading) {
                Button("è¿”å›") {
                    dismiss()
                }
            }
        }
        .onAppear {
            setupPreviewData()
        }
    }
    
    func speakSentence() {
        guard let sentence = sentences.first?.text else { return }
        print("ğŸ”Š é–‹å§‹æœ—è®€å¥å­: \(sentence)")
        
        let utterance = AVSpeechUtterance(string: sentence)
        utterance.voice = AVSpeechSynthesisVoice(language: "zh-TW")
        utterance.rate = 0.5
        utterance.volume = 1.0
        
        synthesizer.speak(utterance)
        print("ğŸ¤ æœ—è®€å·²é–‹å§‹")
    }
    
    // MARK: - é è¦½æ•¸æ“šè¨­ç½®
    private func setupPreviewData() {
        // å¦‚æœæ²’æœ‰æ•¸æ“šï¼Œå‰µå»ºä¸€äº›æ¸¬è©¦æ•¸æ“š
        if sentences.isEmpty {
            let testSentence = Sentence(
                id: "test_sentence_01",
                text: "æ¨¹ä¸Šæœ‰è¨±å¤šè‘‰å­",
                words: ["æ¨¹", "è‘‰"],
                answerPositions: [0, 4],
                storyId: "test_story",
                order: 1
            )
            modelContext.insert(testSentence)
            try? modelContext.save()
        }
    }
}

#Preview(traits: .landscapeLeft) {
    let config = ModelConfiguration(isStoredInMemoryOnly: true)
    let container = try! ModelContainer(for: Sentence.self, configurations: config)
    
    LearningView()
        .modelContainer(container)
}
